{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Squared Test and Pearson Correlation\n",
    "## By: Ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore two important statistical concepts used in data science and feature engineering:\n",
    "\n",
    "1. **Chi-Squared Test (Contingency Test)** - Used to determine if there is a significant association between two categorical variables\n",
    "2. **Pearson Correlation** - Used to measure the linear relationship between numerical variables and identify/remove redundant features\n",
    "\n",
    "These techniques are essential for:\n",
    "- Understanding relationships between variables\n",
    "- Feature selection and dimensionality reduction\n",
    "- Removing redundant attributes from datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chi-Squared Contingency Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Chi-Squared Test?\n",
    "\n",
    "The Chi-Squared test (χ² test) is a statistical hypothesis test that is valid for sampling distributions of a test statistic that follow a chi-squared distribution. It is used to:\n",
    "\n",
    "- Determine if there is a significant association between two categorical variables\n",
    "- Test whether the observed frequencies differ from expected frequencies\n",
    "- Analyze contingency tables (cross-tabulations)\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Null Hypothesis (H₀)**: The two variables are independent (no association)\n",
    "- **Alternative Hypothesis (H₁)**: The two variables are dependent (there is an association)\n",
    "- **p-value**: If p-value < 0.05, we reject the null hypothesis (significant association exists)\n",
    "- **Significance Level (α)**: Usually set to 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset: Titanic\n",
    "\n",
    "Let's use the Titanic dataset to demonstrate the Chi-Squared test. We want to determine if there is a significant association between:\n",
    "- **Gender** and **Survival** (Did gender affect survival rates?)\n",
    "- **Passenger Class** and **Survival** (Did class affect survival rates?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_titanic = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data/titanic.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_titanic.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/io/parsers/readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/io/parsers/readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1904\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1902\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1903\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1904\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1915\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/io/common.py:926\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    922\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    923\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    935\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/titanic.csv'"
     ]
    }
   ],
   "source": [
    "df_titanic = pd.read_csv('./data/titanic.csv')\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test: Gender vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_gender = pd.crosstab(df_titanic['Sex'], df_titanic['Survived'])\n",
    "print(\"Contingency Table: Gender vs Survival\")\n",
    "print(contingency_table_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table_gender)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Chi-Squared Test Results: Gender vs Survival\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Chi-Squared Statistic: {chi2:.4f}\")\n",
    "print(f\"P-Value: {p_value:.4e}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"\\nExpected Frequencies:\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_gender.index, \n",
    "                   columns=contingency_table_gender.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Gender vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "print(\"=\" * 50)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print(f\"P-Value: {p_value:.4e}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nResult: REJECT the null hypothesis (p-value < {alpha})\")\n",
    "    print(\"Conclusion: There IS a significant association between Gender and Survival.\")\n",
    "    print(\"Women were more likely to survive than men.\")\n",
    "else:\n",
    "    print(f\"\\nResult: FAIL TO REJECT the null hypothesis (p-value >= {alpha})\")\n",
    "    print(\"Conclusion: There is NO significant association between Gender and Survival.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test: Passenger Class vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_class = pd.crosstab(df_titanic['Pclass'], df_titanic['Survived'])\n",
    "print(\"Contingency Table: Passenger Class vs Survival\")\n",
    "print(contingency_table_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_class, p_value_class, dof_class, expected_class = chi2_contingency(contingency_table_class)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Chi-Squared Test Results: Passenger Class vs Survival\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Chi-Squared Statistic: {chi2_class:.4f}\")\n",
    "print(f\"P-Value: {p_value_class:.4e}\")\n",
    "print(f\"Degrees of Freedom: {dof_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Passenger Class vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print(f\"P-Value: {p_value_class:.4e}\")\n",
    "\n",
    "if p_value_class < alpha:\n",
    "    print(f\"\\nResult: REJECT the null hypothesis (p-value < {alpha})\")\n",
    "    print(\"Conclusion: There IS a significant association between Passenger Class and Survival.\")\n",
    "    print(\"Higher class passengers were more likely to survive.\")\n",
    "else:\n",
    "    print(f\"\\nResult: FAIL TO REJECT the null hypothesis (p-value >= {alpha})\")\n",
    "    print(\"Conclusion: There is NO significant association.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Chi-Squared Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(contingency_table_gender, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Gender vs Survival\\nChi-Squared Test: p < 0.001')\n",
    "axes[0].set_xlabel('Survived')\n",
    "axes[0].set_ylabel('Gender')\n",
    "\n",
    "sns.heatmap(contingency_table_class, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Passenger Class vs Survival\\nChi-Squared Test: p < 0.001')\n",
    "axes[1].set_xlabel('Survived')\n",
    "axes[1].set_ylabel('Pclass')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pearson Correlation (Removing Attribute Redundancies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Pearson Correlation?\n",
    "\n",
    "The Pearson correlation coefficient (r) measures the linear relationship between two continuous variables:\n",
    "\n",
    "- **Range**: -1 to +1\n",
    "- **+1**: Perfect positive linear relationship\n",
    "- **-1**: Perfect negative linear relationship\n",
    "- **0**: No linear relationship\n",
    "\n",
    "### Why Remove Redundant Features?\n",
    "\n",
    "In feature engineering, when two features are highly correlated:\n",
    "- They provide similar information\n",
    "- They can cause multicollinearity in models\n",
    "- They increase complexity without adding value\n",
    "- Removing one can simplify the model without losing much information\n",
    "\n",
    "### Decision Rule:\n",
    "- If |correlation| > 0.7 to 0.9, consider removing one of the correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Insurance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insurance = pd.read_csv('./data/insurance.csv')\n",
    "print(\"Insurance Dataset:\")\n",
    "print(f\"Shape: {df_insurance.shape}\")\n",
    "print(\"\\nColumns:\")\n",
    "print(df_insurance.dtypes)\n",
    "df_insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df_insurance.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_encoded['sex'] = le.fit_transform(df_encoded['sex'])\n",
    "df_encoded['smoker'] = le.fit_transform(df_encoded['smoker'])\n",
    "df_encoded['region'] = le.fit_transform(df_encoded['region'])\n",
    "\n",
    "print(\"Encoded Dataset:\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Pearson Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_encoded.corr(method='pearson')\n",
    "\n",
    "print(\"Pearson Correlation Matrix:\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            linewidths=0.5)\n",
    "plt.title('Pearson Correlation Matrix - Insurance Dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "print(f\"Finding highly correlated features (|r| > {threshold}):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "highly_correlated = []\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            col1 = correlation_matrix.columns[i]\n",
    "            col2 = correlation_matrix.columns[j]\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            highly_correlated.append((col1, col2, corr_value))\n",
    "            print(f\"  {col1} ↔ {col2}: {corr_value:.3f}\")\n",
    "\n",
    "if not highly_correlated:\n",
    "    print(\"  No highly correlated feature pairs found in this dataset.\")\n",
    "    print(\"\\nNote: In this dataset, the highest correlation is:\")\n",
    "    corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_pairs.append((correlation_matrix.columns[i], \n",
    "                            correlation_matrix.columns[j], \n",
    "                            correlation_matrix.iloc[i, j]))\n",
    "    corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    for pair in corr_pairs[:3]:\n",
    "        print(f\"  {pair[0]} ↔ {pair[1]}: {pair[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Another Dataset: Auto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto = pd.read_csv('./data/Auto.csv')\n",
    "print(\"Auto Dataset:\")\n",
    "print(f\"Shape: {df_auto.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_auto.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric columns: {numeric_cols}\")\n",
    "\n",
    "df_auto_numeric = df_auto[numeric_cols].dropna()\n",
    "auto_corr = df_auto_numeric.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(auto_corr, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            linewidths=0.5)\n",
    "plt.title('Pearson Correlation Matrix - Auto Dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Redundant Features in Auto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "print(f\"Identifying highly correlated features (|r| > {threshold}):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "auto_highly_correlated = []\n",
    "\n",
    "for i in range(len(auto_corr.columns)):\n",
    "    for j in range(i+1, len(auto_corr.columns)):\n",
    "        if abs(auto_corr.iloc[i, j]) > threshold:\n",
    "            col1 = auto_corr.columns[i]\n",
    "            col2 = auto_corr.columns[j]\n",
    "            corr_value = auto_corr.iloc[i, j]\n",
    "            auto_highly_correlated.append((col1, col2, corr_value))\n",
    "            print(f\"  {col1} ↔ {col2}: {corr_value:.3f}\")\n",
    "\n",
    "print(f\"\\nTotal highly correlated pairs found: {len(auto_highly_correlated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Redundant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Remove features that are highly correlated with each other.\n",
    "    Keeps the first feature and removes the others.\n",
    "    \"\"\"\n",
    "    corr_matrix = df.corr(method='pearson').abs()\n",
    "    \n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    \n",
    "    return to_drop\n",
    "\n",
    "features_to_drop = remove_correlated_features(df_auto_numeric, threshold=0.7)\n",
    "\n",
    "print(f\"Features to remove (correlation > 0.7): {features_to_drop}\")\n",
    "print(f\"\\nOriginal number of features: {len(df_auto_numeric.columns)}\")\n",
    "print(f\"Features to remove: {len(features_to_drop)}\")\n",
    "print(f\"Remaining features: {len(df_auto_numeric.columns) - len(features_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_auto_numeric.drop(columns=features_to_drop)\n",
    "print(\"\\nReduced Dataset (after removing redundant features):\")\n",
    "print(f\"Columns: {df_reduced.columns.tolist()}\")\n",
    "print(f\"Shape: {df_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "\n",
    "#### Chi-Squared Test:\n",
    "- Used to test independence between categorical variables\n",
    "- Creates contingency tables from categorical data\n",
    "- Compares observed vs expected frequencies\n",
    "- If p-value < 0.05: reject null hypothesis (variables are dependent)\n",
    "- If p-value >= 0.05: fail to reject null hypothesis (variables are independent)\n",
    "\n",
    "#### Pearson Correlation:\n",
    "- Measures linear relationship between numerical variables\n",
    "- Range: -1 (negative) to +1 (positive)\n",
    "- Used to identify and remove redundant features\n",
    "- High correlation (|r| > 0.7) suggests redundancy\n",
    "- Can simplify models by removing correlated features\n",
    "\n",
    "#### Practical Applications:\n",
    "- Feature selection for machine learning models\n",
    "- Data preprocessing and cleaning\n",
    "- Understanding variable relationships in exploratory data analysis (EDA)\n",
    "- Reducing multicollinearity in regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References:\n",
    "\n",
    "- SciPy Documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
    "- Pandas Documentation: https://pandas.pydata.org/docs/\n",
    "- Seaborn Documentation: https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Notebook created by: Ali**\n",
    "**Date: February 2026**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
