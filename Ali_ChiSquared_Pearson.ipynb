{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Squared Test and Pearson Correlation\n",
    "## Group 3 - By: Ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Course: PROG8245 Data Integration Workshop\n",
    "## Topic: Chi-Squared Contingency Test and Pearson Correlation\n",
    "## Date: February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore two important statistical concepts used in data science and feature engineering:\n",
    "\n",
    "1. **Chi-Squared Test (Contingency Test)** - Used to determine if there is a significant association between two categorical variables\n",
    "2. **Pearson Correlation** - Used to measure the linear relationship between numerical variables and identify/remove redundant features\n",
    "\n",
    "These techniques are essential for:\n",
    "- Understanding relationships between variables\n",
    "- Feature selection and dimensionality reduction\n",
    "- Removing redundant attributes from datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Chi-Squared Contingency Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Chi-Squared Test?\n",
    "\n",
    "The Chi-Squared test (χ² test) is a statistical hypothesis test that is valid for sampling distributions of a test statistic that follow a chi-squared distribution. It is used to:\n",
    "\n",
    "- Determine if there is a significant association between two categorical variables\n",
    "- Test whether the observed frequencies differ from expected frequencies\n",
    "- Analyze contingency tables (cross-tabulations)\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Null Hypothesis (H₀)**: The two variables are independent (no association)\n",
    "- **Alternative Hypothesis (H₁)**: The two variables are dependent (there is an association)\n",
    "- **p-value**: If p-value < 0.05, we reject the null hypothesis (significant association exists)\n",
    "- **Significance Level (α)**: Usually set to 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset: Titanic\n",
    "\n",
    "Let's use the Titanic dataset to demonstrate the Chi-Squared test. We want to determine if there is a significant association between:\n",
    "- **Gender** and **Survival** (Did gender affect survival rates?)\n",
    "- **Passenger Class** and **Survival** (Did class affect survival rates?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('reference/DataIntegrationWorkshop/data/titanic.csv')\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test: Gender vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_gender = pd.crosstab(df_titanic['Sex'], df_titanic['Survived'])\n",
    "print(\"Contingency Table: Gender vs Survival\")\n",
    "print(contingency_table_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table_gender)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Chi-Squared Test Results: Gender vs Survival\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Chi-Squared Statistic: {chi2:.4f}\")\n",
    "print(f\"P-Value: {p_value:.4e}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"\\nExpected Frequencies:\")\n",
    "print(pd.DataFrame(expected, \n",
    "                   index=contingency_table_gender.index, \n",
    "                   columns=contingency_table_gender.columns).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Gender vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "print(\"=\" * 50)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print(f\"P-Value: {p_value:.4e}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nResult: REJECT the null hypothesis (p-value < {alpha})\")\n",
    "    print(\"Conclusion: There IS a significant association between Gender and Survival.\")\n",
    "    print(\"Women were more likely to survive than men.\")\n",
    "else:\n",
    "    print(f\"\\nResult: FAIL TO REJECT the null hypothesis (p-value >= {alpha})\")\n",
    "    print(\"Conclusion: There is NO significant association between Gender and Survival.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test: Passenger Class vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_class = pd.crosstab(df_titanic['Pclass'], df_titanic['Survived'])\n",
    "print(\"Contingency Table: Passenger Class vs Survival\")\n",
    "print(contingency_table_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_class, p_value_class, dof_class, expected_class = chi2_contingency(contingency_table_class)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Chi-Squared Test Results: Passenger Class vs Survival\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Chi-Squared Statistic: {chi2_class:.4f}\")\n",
    "print(f\"P-Value: {p_value_class:.4e}\")\n",
    "print(f\"Degrees of Freedom: {dof_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Passenger Class vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Significance Level (α): {alpha}\")\n",
    "print(f\"P-Value: {p_value_class:.4e}\")\n",
    "\n",
    "if p_value_class < alpha:\n",
    "    print(f\"\\nResult: REJECT the null hypothesis (p-value < {alpha})\")\n",
    "    print(\"Conclusion: There IS a significant association between Passenger Class and Survival.\")\n",
    "    print(\"Higher class passengers were more likely to survive.\")\n",
    "else:\n",
    "    print(f\"\\nResult: FAIL TO REJECT the null hypothesis (p-value >= {alpha})\")\n",
    "    print(\"Conclusion: There is NO significant association.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Chi-Squared Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(contingency_table_gender, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Gender vs Survival\\nChi-Squared Test: p < 0.001')\n",
    "axes[0].set_xlabel('Survived')\n",
    "axes[0].set_ylabel('Gender')\n",
    "\n",
    "sns.heatmap(contingency_table_class, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Passenger Class vs Survival\\nChi-Squared Test: p < 0.001')\n",
    "axes[1].set_xlabel('Survived')\n",
    "axes[1].set_ylabel('Pclass')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Pearson Correlation (Removing Attribute Redundancies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Pearson Correlation?\n",
    "\n",
    "The Pearson correlation coefficient (r) measures the linear relationship between two continuous variables:\n",
    "\n",
    "- **Range**: -1 to +1\n",
    "- **+1**: Perfect positive linear relationship\n",
    "- **-1**: Perfect negative linear relationship\n",
    "- **0**: No linear relationship\n",
    "\n",
    "### Why Remove Redundant Features?\n",
    "\n",
    "In feature engineering, when two features are highly correlated:\n",
    "- They provide similar information\n",
    "- They can cause multicollinearity in models\n",
    "- They increase complexity without adding value\n",
    "- Removing one can simplify the model without losing much information\n",
    "\n",
    "### Decision Rule:\n",
    "- If |correlation| > 0.7 to 0.9, consider removing one of the correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Insurance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insurance = pd.read_csv('reference/DataIntegrationWorkshop/data/insurance.csv')\n",
    "print(\"Insurance Dataset:\")\n",
    "print(f\"Shape: {df_insurance.shape}\")\n",
    "print(\"\\nColumns:\")\n",
    "print(df_insurance.dtypes)\n",
    "df_insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df_insurance.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_encoded['sex'] = le.fit_transform(df_encoded['sex'])\n",
    "df_encoded['smoker'] = le.fit_transform(df_encoded['smoker'])\n",
    "df_encoded['region'] = le.fit_transform(df_encoded['region'])\n",
    "\n",
    "print(\"Encoded Dataset:\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Pearson Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_encoded.corr(method='pearson')\n",
    "\n",
    "print(\"Pearson Correlation Matrix:\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            linewidths=0.5)\n",
    "plt.title('Pearson Correlation Matrix - Insurance Dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "print(f\"Finding highly correlated features (|r| > {threshold}):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "highly_correlated = []\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            col1 = correlation_matrix.columns[i]\n",
    "            col2 = correlation_matrix.columns[j]\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            highly_correlated.append((col1, col2, corr_value))\n",
    "            print(f\"  {col1} ↔ {col2}: {corr_value:.3f}\")\n",
    "\n",
    "if not highly_correlated:\n",
    "    print(\"  No highly correlated feature pairs found in this dataset.\")\n",
    "    print(\"\\nNote: In this dataset, the highest correlations are:\")\n",
    "    corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_pairs.append((correlation_matrix.columns[i], \n",
    "                            correlation_matrix.columns[j], \n",
    "                            correlation_matrix.iloc[i, j]))\n",
    "    corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    for pair in corr_pairs[:3]:\n",
    "        print(f\"  {pair[0]} ↔ {pair[1]}: {pair[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Another Dataset: Auto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto = pd.read_csv('reference/DataIntegrationWorkshop/data/Auto.csv')\n",
    "print(\"Auto Dataset:\")\n",
    "print(f\"Shape: {df_auto.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_auto.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric columns: {numeric_cols}\")\n",
    "\n",
    "df_auto_numeric = df_auto[numeric_cols].dropna()\n",
    "auto_corr = df_auto_numeric.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(auto_corr, annot=True, cmap='coolwarm', center=0, fmt='.2f',\n",
    "            linewidths=0.5)\n",
    "plt.title('Pearson Correlation Matrix - Auto Dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Redundant Features in Auto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "print(f\"Identifying highly correlated features (|r| > {threshold}):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "auto_highly_correlated = []\n",
    "\n",
    "for i in range(len(auto_corr.columns)):\n",
    "    for j in range(i+1, len(auto_corr.columns)):\n",
    "        if abs(auto_corr.iloc[i, j]) > threshold:\n",
    "            col1 = auto_corr.columns[i]\n",
    "            col2 = auto_corr.columns[j]\n",
    "            corr_value = auto_corr.iloc[i, j]\n",
    "            auto_highly_correlated.append((col1, col2, corr_value))\n",
    "            print(f\"  {col1} ↔ {col2}: {corr_value:.3f}\")\n",
    "\n",
    "print(f\"\\nTotal highly correlated pairs found: {len(auto_highly_correlated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Redundant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Remove features that are highly correlated with each other.\n",
    "    Keeps the first feature and removes the others.\n",
    "    \"\"\"\n",
    "    corr_matrix = df.corr(method='pearson').abs()\n",
    "    \n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    \n",
    "    return to_drop\n",
    "\n",
    "features_to_drop = remove_correlated_features(df_auto_numeric, threshold=0.7)\n",
    "\n",
    "print(f\"Features to remove (correlation > 0.7): {features_to_drop}\")\n",
    "print(f\"\\nOriginal number of features: {len(df_auto_numeric.columns)}\")\n",
    "print(f\"Features to remove: {len(features_to_drop)}\")\n",
    "print(f\"Remaining features: {len(df_auto_numeric.columns) - len(features_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_auto_numeric.drop(columns=features_to_drop)\n",
    "print(\"\\nReduced Dataset (after removing redundant features):\")\n",
    "print(f\"Columns: {df_reduced.columns.tolist()}\")\n",
    "print(f\"Shape: {df_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "\n",
    "#### Chi-Squared Test:\n",
    "- Used to test independence between categorical variables\n",
    "- Creates contingency tables from categorical data\n",
    "- Compares observed vs expected frequencies\n",
    "- If p-value < 0.05: reject null hypothesis (variables are dependent)\n",
    "- If p-value >= 0.05: fail to reject null hypothesis (variables are independent)\n",
    "\n",
    "#### Pearson Correlation:\n",
    "- Measures linear relationship between numerical variables\n",
    "- Range: -1 (negative) to +1 (positive)\n",
    "- Used to identify and remove redundant features\n",
    "- High correlation (|r| > 0.7) suggests redundancy\n",
    "- Can simplify models by removing correlated features\n",
    "\n",
    "#### Practical Applications:\n",
    "- Feature selection for machine learning models\n",
    "- Data preprocessing and cleaning\n",
    "- Understanding variable relationships in exploratory data analysis (EDA)\n",
    "- Reducing multicollinearity in regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References:\n",
    "\n",
    "- SciPy Documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\n",
    "- Pandas Documentation: https://pandas.pydata.org/docs/\n",
    "- Seaborn Documentation: https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Notebook created by: Ali (Group 3)**\n",
    "**Course: PROG8245 Data Integration Workshop**\n",
    "**Date: February 2026**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
